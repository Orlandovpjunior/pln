{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2U0JdrvbIX9"
      },
      "source": [
        "# Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTLuguKUuwzu"
      },
      "source": [
        "\n",
        "\n",
        "*   **Aluno**: Seu nome\n",
        "*   **Matrícula**: Sua Matrícula\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smGMQon0u937"
      },
      "source": [
        "# Representação Vetorial de Textos em PLN\n",
        "\n",
        "A linguagem humana é rica, ambígua e altamente contextual. No entanto, para que computadores consigam processar, comparar ou aprender com textos, é necessário traduzi-los para uma linguagem que as máquinas compreendam: **números**.\n",
        "\n",
        "É aí que entram os **modelos vetoriais de representação textual**, que transformam palavras, frases ou documentos em **vetores numéricos**. Essa etapa é chamada de **vetorização**.\n",
        "\n",
        "Neste laboratório, você vai explorar a evolução das representações vetoriais utilizadas no Processamento de Linguagem Natural (PLN), entendendo como passamos de abordagens simples, como **One-Hot Encoding**, para técnicas mais expressivas como **TF-IDF**, além de aplicar **métricas de similaridade** e algoritmos como o **KNN** para classificar textos.\n",
        "\n",
        "Vamos colocar a mão na massa e ver na prática como representar textos como vetores e extrair sentido dessa nova forma de ver a linguagem!\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpFHOxV0x26c"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "PkQf53kGx41e"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77hpSeOW36kn"
      },
      "source": [
        "## Funções"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "7fdJK36V38MF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def similaridade_cosseno(v1, v2):\n",
        "    v1 = np.array(v1)\n",
        "    v2 = np.array(v2)\n",
        "    numerador = np.dot(v1, v2)\n",
        "    denominador = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
        "    return numerador / denominador if denominador != 0 else 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkG-ZYspwIjl"
      },
      "source": [
        "## Exemplo com DataSet Simples\n",
        "\n",
        "Antes de começarmos a vetorização, precisamos de um conjunto de textos para trabalhar. Para isso, vamos utilizar um **mini-corpus com 15 frases curtas**, que simulam situações do cotidiano envolvendo animais, ambientes e clima.\n",
        "\n",
        "Esse conjunto foi pensado para conter:\n",
        "- Palavras repetidas e variações sutis (como \"gato\" e \"gata\", \"chuva\" e \"molhado\"),\n",
        "- Frases com temas comuns (sofá, quintal, jardim),\n",
        "- E expressões que nos permitem testar **similaridade**, **frequência** e **contexto**.\n",
        "\n",
        "A ideia é que esse corpus nos ajude a enxergar, de forma prática, como diferentes técnicas de vetorização representam os textos e como elas capturam (ou não) relações entre palavras e frases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "lqdb18VNwHvM"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"o gato dorme no sofá, com o outro gato\",\n",
        "    \"o cachorro late no quintal\",\n",
        "    \"a gata correu pelo jardim, com a outra gata\",\n",
        "    \"o sofá é confortável\",\n",
        "    \"meu cachorro gosta de correr\",\n",
        "    \"gatos e cachorros são animais domésticos\",\n",
        "    \"o quintal e as árvores está molhado por causa da chuva\",\n",
        "    \"choveu muito no final de semana\",\n",
        "    \"meu gato gosta de dormir o dia todo\",\n",
        "    \"animais gostam de brincar no jardim\",\n",
        "    \"o dia está ensolarado e quente\",\n",
        "    \"a chuva deixou tudo molhado\",\n",
        "    \"meus animais dormem juntos no sofá\",\n",
        "    \"o jardim tem flores e árvores e as árvores são frutíferas\",\n",
        "    \"o cachorro de Maria subiu no sofá\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YYazBq9y0zS"
      },
      "source": [
        "### **Vetorização de dados textuais**\n",
        "\n",
        "Nesta seção, você deve executar três tipos diferentes de vetorização: o ***One-hot Encoding***, o ***Term Frequency* (TF)** e o ***Term Frequency-Inverse Document Frequency* (TF-IDF)**. Após descrever as características e o funcionamento dessas vetorizações, aplique-as aos documentos da variável **`response`** do conjunto de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLjMJuYRvLLd"
      },
      "source": [
        "#### One Hot Encoding\n",
        "\n",
        "A técnica de **One-Hot Encoding** é uma das formas mais simples de representar palavras como vetores. Nela, cada palavra do vocabulário é representada por um vetor binário com a mesma dimensão do vocabulário — e apenas uma posição é \"1\", indicando a presença da palavra.\n",
        "\n",
        "Abaixo, aplicamos One-Hot Encoding para cada **palavra única** do nosso corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "kRMMCC2EurfL"
      },
      "outputs": [],
      "source": [
        "# Inicializando o vetorizador com o binary = true para que as colunas geradas possuam um valor binário e não um valor de contagem\n",
        "vectorizer_one_hot = CountVectorizer(binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "9hQc0JjFzLtc"
      },
      "outputs": [],
      "source": [
        "# Vetorizando o dataset\n",
        "one_hot_response = vectorizer_one_hot.fit_transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(15, 53)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_hot_response.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "_sTSE8YzzTyM"
      },
      "outputs": [],
      "source": [
        "# Gerando um dataframe com o dataset vetorizado\n",
        "one_hot_df = pd.DataFrame(one_hot_response.toarray(), columns=vectorizer_one_hot.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "RWsERjG9zqak",
        "outputId": "52f03122-3e99-49e4-9a8c-7ccd82d5bd90"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>animais</th>\n",
              "      <th>as</th>\n",
              "      <th>brincar</th>\n",
              "      <th>cachorro</th>\n",
              "      <th>cachorros</th>\n",
              "      <th>causa</th>\n",
              "      <th>choveu</th>\n",
              "      <th>chuva</th>\n",
              "      <th>com</th>\n",
              "      <th>confortável</th>\n",
              "      <th>...</th>\n",
              "      <th>quente</th>\n",
              "      <th>quintal</th>\n",
              "      <th>semana</th>\n",
              "      <th>sofá</th>\n",
              "      <th>subiu</th>\n",
              "      <th>são</th>\n",
              "      <th>tem</th>\n",
              "      <th>todo</th>\n",
              "      <th>tudo</th>\n",
              "      <th>árvores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15 rows × 53 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    animais  as  brincar  cachorro  cachorros  causa  choveu  chuva  com  \\\n",
              "0         0   0        0         0          0      0       0      0    1   \n",
              "1         0   0        0         1          0      0       0      0    0   \n",
              "2         0   0        0         0          0      0       0      0    1   \n",
              "3         0   0        0         0          0      0       0      0    0   \n",
              "4         0   0        0         1          0      0       0      0    0   \n",
              "5         1   0        0         0          1      0       0      0    0   \n",
              "6         0   1        0         0          0      1       0      1    0   \n",
              "7         0   0        0         0          0      0       1      0    0   \n",
              "8         0   0        0         0          0      0       0      0    0   \n",
              "9         1   0        1         0          0      0       0      0    0   \n",
              "10        0   0        0         0          0      0       0      0    0   \n",
              "11        0   0        0         0          0      0       0      1    0   \n",
              "12        1   0        0         0          0      0       0      0    0   \n",
              "13        0   1        0         0          0      0       0      0    0   \n",
              "14        0   0        0         1          0      0       0      0    0   \n",
              "\n",
              "    confortável  ...  quente  quintal  semana  sofá  subiu  são  tem  todo  \\\n",
              "0             0  ...       0        0       0     1      0    0    0     0   \n",
              "1             0  ...       0        1       0     0      0    0    0     0   \n",
              "2             0  ...       0        0       0     0      0    0    0     0   \n",
              "3             1  ...       0        0       0     1      0    0    0     0   \n",
              "4             0  ...       0        0       0     0      0    0    0     0   \n",
              "5             0  ...       0        0       0     0      0    1    0     0   \n",
              "6             0  ...       0        1       0     0      0    0    0     0   \n",
              "7             0  ...       0        0       1     0      0    0    0     0   \n",
              "8             0  ...       0        0       0     0      0    0    0     1   \n",
              "9             0  ...       0        0       0     0      0    0    0     0   \n",
              "10            0  ...       1        0       0     0      0    0    0     0   \n",
              "11            0  ...       0        0       0     0      0    0    0     0   \n",
              "12            0  ...       0        0       0     1      0    0    0     0   \n",
              "13            0  ...       0        0       0     0      0    1    1     0   \n",
              "14            0  ...       0        0       0     1      1    0    0     0   \n",
              "\n",
              "    tudo  árvores  \n",
              "0      0        0  \n",
              "1      0        0  \n",
              "2      0        0  \n",
              "3      0        0  \n",
              "4      0        0  \n",
              "5      0        0  \n",
              "6      0        1  \n",
              "7      0        0  \n",
              "8      0        0  \n",
              "9      0        0  \n",
              "10     0        0  \n",
              "11     1        0  \n",
              "12     0        0  \n",
              "13     0        1  \n",
              "14     0        0  \n",
              "\n",
              "[15 rows x 53 columns]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Plotando o dataset vetorizado\n",
        "one_hot_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbDIPRbw0TsL"
      },
      "source": [
        "# Agora é sua vez\n",
        "\n",
        "Utilizando um DataSet de comentários do IMDB, vamos transformar cada comentário em um vetor e calcular similaridades com métricas diferentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "DqCvQKw7uFrm",
        "outputId": "990c6794-2d3f-47da-8017-bd6fe0707ed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantidade de comentários 1000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one reviewer mention watch oz episode youll ho...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wonderful little production film technique una...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically there family little boy jake think t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter matteis love time money visually stun f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  one reviewer mention watch oz episode youll ho...          1\n",
              "1  wonderful little production film technique una...          1\n",
              "2  thought wonderful way spend time hot summer we...          1\n",
              "3  basically there family little boy jake think t...          0\n",
              "4  petter matteis love time money visually stun f...          1"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/Karthik-Bhaskar/Sentiment-Analysis/refs/heads/master/processed.csv'\n",
        "df = pd.read_csv(url)\n",
        "df = df.head(1000)\n",
        "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "print('Quantidade de comentários', df.shape[0])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdjpaV-ou9pa"
      },
      "source": [
        "## 1. Para cada texto do dataset do IMDB, transforme-o em sua versão vetorizada binária."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one reviewer mention watch oz episode youll ho...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wonderful little production film technique una...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically there family little boy jake think t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter matteis love time money visually stun f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>nothing sacred ask ernie fosselius day everybo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>hat hate selfaware pretentious inanity masquer...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>usually try professional constructive criticiz...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>like go see film history class something like ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>like zoology textbook give depiction animal ac...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                review  sentiment\n",
              "0    one reviewer mention watch oz episode youll ho...          1\n",
              "1    wonderful little production film technique una...          1\n",
              "2    thought wonderful way spend time hot summer we...          1\n",
              "3    basically there family little boy jake think t...          0\n",
              "4    petter matteis love time money visually stun f...          1\n",
              "..                                                 ...        ...\n",
              "995  nothing sacred ask ernie fosselius day everybo...          1\n",
              "996  hat hate selfaware pretentious inanity masquer...          0\n",
              "997  usually try professional constructive criticiz...          0\n",
              "998  like go see film history class something like ...          0\n",
              "999  like zoology textbook give depiction animal ac...          0\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldUuaMqA0ZrV",
        "outputId": "aa90c63d-6ad1-4202-d272-6bd07b539e48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['aaargh' 'aaliyah' 'aamir' 'aaron' 'ab' 'abandon' 'abba' 'abbey' 'abbot'\n",
            " 'abbott']\n"
          ]
        }
      ],
      "source": [
        "#É possível vetorizar o informações do dataframe passando seu dataframe['nome_coluna'] como parâmetro para seu vetorizador\n",
        "#Você pode utilizar o vetorizador presente no exemplo acima de nome e salvar os vetores na variável one_hot_response\n",
        "#Recupere cada palavra resultante da vetorização. Dica: use a função get_feature_names_out() do seu vetorizador\n",
        "one_hot_response = vectorizer_one_hot.fit_transform(df['review'])\n",
        "one_hot_df = pd.DataFrame(one_hot_response.toarray(), columns=vectorizer_one_hot.get_feature_names_out())\n",
        "words = vectorizer_one_hot.get_feature_names_out()\n",
        "print(words[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "gPjLx4l40iIQ",
        "outputId": "9d79ff52-cbc4-49a6-a257-6cbb8813bdad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aaargh</th>\n",
              "      <th>aaliyah</th>\n",
              "      <th>aamir</th>\n",
              "      <th>aaron</th>\n",
              "      <th>ab</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abba</th>\n",
              "      <th>abbey</th>\n",
              "      <th>abbot</th>\n",
              "      <th>abbott</th>\n",
              "      <th>...</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zoology</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zp</th>\n",
              "      <th>zu</th>\n",
              "      <th>zucker</th>\n",
              "      <th>zulu</th>\n",
              "      <th>zwick</th>\n",
              "      <th>zzzzzzzzzzzzzzzzzz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 17431 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   aaargh  aaliyah  aamir  aaron  ab  abandon  abba  abbey  abbot  abbott  \\\n",
              "0       0        0      0      0   0        0     0      0      0       0   \n",
              "1       0        0      0      0   0        0     0      0      0       0   \n",
              "2       0        0      0      0   0        0     0      0      0       0   \n",
              "3       0        0      0      0   0        0     0      0      0       0   \n",
              "4       0        0      0      0   0        0     0      0      0       0   \n",
              "\n",
              "   ...  zone  zoo  zoology  zoom  zp  zu  zucker  zulu  zwick  \\\n",
              "0  ...     0    0        0     0   0   0       0     0      0   \n",
              "1  ...     0    0        0     0   0   0       0     0      0   \n",
              "2  ...     0    0        0     0   0   0       0     0      0   \n",
              "3  ...     0    0        0     0   0   0       0     0      0   \n",
              "4  ...     0    0        0     0   0   0       0     0      0   \n",
              "\n",
              "   zzzzzzzzzzzzzzzzzz  \n",
              "0                   0  \n",
              "1                   0  \n",
              "2                   0  \n",
              "3                   0  \n",
              "4                   0  \n",
              "\n",
              "[5 rows x 17431 columns]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Transforme seus vetores em um dataframe para trabalhar com essa estrutura de dados. Use os vetores da célula anterior e as palavras obtidas para criar o dataframe\n",
        "#Você pode fazer isso chamando a classe pd.DataFrame(vetores.toarray(), columns=['nome de cada coluna'])\n",
        "\n",
        "\n",
        "one_hot_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFO_WJ-o0Wz5",
        "outputId": "a4610ad2-3ece-4942-964b-b32f5e751bf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['accustom', 'agenda', 'agreement', 'appeal', 'around', 'audience', 'away', 'awayi', 'become', 'bitch']\n"
          ]
        }
      ],
      "source": [
        "# Recupere o primeiro documento para a variável d1\n",
        "# Você pode fazer isso, recuperando o elemento índice 0 no dataframe usando loc.\n",
        "\n",
        "# Imprima quais palavras fazem parte do vetor de d1\n",
        "# Para imprimir as palavras você pode percorrer cada posição desse vetor. Se ele for 1, então você pode manter sua palavra usando o atributo index do d1\n",
        "\n",
        "d1 = one_hot_df.loc[0]\n",
        "\n",
        "d1_words = [token for token, value in d1.items() if value == 1]\n",
        "\n",
        "print(d1_words[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aaargh</th>\n",
              "      <th>aaliyah</th>\n",
              "      <th>aamir</th>\n",
              "      <th>aaron</th>\n",
              "      <th>ab</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abba</th>\n",
              "      <th>abbey</th>\n",
              "      <th>abbot</th>\n",
              "      <th>abbott</th>\n",
              "      <th>...</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zoology</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zp</th>\n",
              "      <th>zu</th>\n",
              "      <th>zucker</th>\n",
              "      <th>zulu</th>\n",
              "      <th>zwick</th>\n",
              "      <th>zzzzzzzzzzzzzzzzzz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>999 rows × 17431 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     aaargh  aaliyah  aamir  aaron  ab  abandon  abba  abbey  abbot  abbott  \\\n",
              "1         0        0      0      0   0        0     0      0      0       0   \n",
              "2         0        0      0      0   0        0     0      0      0       0   \n",
              "3         0        0      0      0   0        0     0      0      0       0   \n",
              "4         0        0      0      0   0        0     0      0      0       0   \n",
              "5         0        0      0      0   0        0     0      0      0       0   \n",
              "..      ...      ...    ...    ...  ..      ...   ...    ...    ...     ...   \n",
              "995       0        0      0      0   0        0     0      0      0       0   \n",
              "996       0        0      0      0   0        0     0      0      0       0   \n",
              "997       0        0      0      0   0        0     0      0      0       0   \n",
              "998       0        0      0      0   0        0     0      0      0       0   \n",
              "999       0        0      0      0   0        0     0      0      0       0   \n",
              "\n",
              "     ...  zone  zoo  zoology  zoom  zp  zu  zucker  zulu  zwick  \\\n",
              "1    ...     0    0        0     0   0   0       0     0      0   \n",
              "2    ...     0    0        0     0   0   0       0     0      0   \n",
              "3    ...     0    0        0     0   0   0       0     0      0   \n",
              "4    ...     0    0        0     0   0   0       0     0      0   \n",
              "5    ...     0    0        0     0   0   0       0     0      0   \n",
              "..   ...   ...  ...      ...   ...  ..  ..     ...   ...    ...   \n",
              "995  ...     0    0        0     0   0   0       0     0      0   \n",
              "996  ...     0    0        0     0   0   0       0     0      0   \n",
              "997  ...     0    0        0     0   0   0       0     0      0   \n",
              "998  ...     0    0        0     0   0   0       0     0      0   \n",
              "999  ...     0    0        1     0   0   0       0     0      0   \n",
              "\n",
              "     zzzzzzzzzzzzzzzzzz  \n",
              "1                     0  \n",
              "2                     0  \n",
              "3                     0  \n",
              "4                     0  \n",
              "5                     0  \n",
              "..                  ...  \n",
              "995                   0  \n",
              "996                   0  \n",
              "997                   0  \n",
              "998                   0  \n",
              "999                   0  \n",
              "\n",
              "[999 rows x 17431 columns]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_hot_df.iloc[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq2VZ5K40nJI",
        "outputId": "7d8a9792-e4f3-4e42-8079-bdf24b2f4595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Produto escalar: 32\n",
            "Id do documento: 263\n",
            "\n",
            "Similaridade do cosseno: 0.1604\n",
            "Id do documento: 308\n"
          ]
        }
      ],
      "source": [
        "# Encontre o id do documento mais similar ao documento d1 percorrendo o restante do dataframe e retorne seu índice\n",
        "# Utilize o produto escalar e a similaridade do cosseno da função já disponível para achar os documentos similares por essas duas métricas\n",
        "# Calcule cada similaridade separadamente e verifique se o documento retornado é igual\n",
        "\n",
        "#Variáveis para armazenar o id e a similaridade do documento mais similar conforme a similaridade do cosseno\n",
        "sim_cos = -1\n",
        "id_sc = -1\n",
        "\n",
        "#Variáveis para armazenar o id e a similaridade do documento mais similar conforme o produto escalar\n",
        "prod_esc = -1\n",
        "id_pe = -1\n",
        "\n",
        "for idx, row in one_hot_df.iloc[1:].iterrows():\n",
        "\n",
        "  #Calcule o produto escalar e salve o documento de maior similaridade\n",
        "  #Você pode usar a função np.dot() passando seus vetores para calcular o produto escalar\n",
        "  novo_esc = np.dot(d1, row)\n",
        "  \n",
        "  if novo_esc > prod_esc:\n",
        "    prod_esc = novo_esc\n",
        "    id_pe = idx\n",
        "\n",
        "\n",
        "  #Calcule a Similaridade do cosseno e salve o documento de maior similaridade\n",
        "  #Você pode usar a função de similaridade do cosseno presente no início deste notebook passando seus vetores\n",
        "  novo_cos = similaridade_cosseno(d1, row)\n",
        "  \n",
        "  if novo_cos > sim_cos:\n",
        "    sim_cos = novo_cos\n",
        "    id_sc = idx\n",
        "\n",
        "\n",
        "print(f\"Produto escalar: {prod_esc}\")\n",
        "print(\"Id do documento:\", id_pe)\n",
        "print()\n",
        "print(f\"Similaridade do cosseno: {sim_cos:.4f}\")\n",
        "print(\"Id do documento:\", id_sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMvwH3h0_87w",
        "outputId": "e5705ed0-14ea-45c9-8343-c2df79d6b7ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abandon', 'able', 'act', 'activity', 'al', 'alarm', 'allow', 'also', 'amaze', 'ambition']\n"
          ]
        }
      ],
      "source": [
        "# Mostre as 10 primeiras palavras presentes do documento que possui maior similaridade conforme o produto escalar\n",
        "# Você pode recuperar esse vetor usando o índice salvo em id_pe\n",
        "\n",
        "d_sim_pe_aux = one_hot_df.loc[id_pe]\n",
        "d_sim_pe_words = [token for token, value in d_sim_pe_aux.items() if value == 1]\n",
        "\n",
        "print(d_sim_pe_words[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kWsfObB0qxT",
        "outputId": "06b7e794-fa14-407f-df13-ece22e7c25d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['action', 'case', 'character', 'cool', 'else', 'excuse', 'extreme', 'fall', 'fun', 'gratuitous']\n"
          ]
        }
      ],
      "source": [
        "# Mostre as 10 primeiras palavras presentes do documento retornado por possuir maior similaridade do cosseno\n",
        "# Você pode recuperar esse vetor usando o índice salvo em id_sc\n",
        "d_sim_cos_aux = one_hot_df.loc[id_sc]\n",
        "d_sim_cos_words = [token for token, value in d_sim_cos_aux.items() if value == 1]\n",
        "print(d_sim_cos_words[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "SUhFrh51CKoK"
      },
      "outputs": [],
      "source": [
        "#Implemente o cálculo da similaridade de Jaccard\n",
        "#Lembre que a similaridade é calculada considerando |A intersect B|/|A union B|\n",
        "#Você pode utilizar os recursos da classe set() do python\n",
        "\n",
        "def similaridade_jaccard(v1: set, v2: set):\n",
        "    \n",
        "    intersection = v1.intersection(v2)\n",
        "    union = v1.union(v2)\n",
        "\n",
        "    len_intersection = len(intersection)\n",
        "    len_union = len(union)\n",
        "\n",
        "    if len_union == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return len_intersection / len_union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BEnmzge4OKm",
        "outputId": "e128994f-d642-4b40-e06c-606bd2b48797"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similaridade de Jaccard: 0.0764\n"
          ]
        }
      ],
      "source": [
        "# Calcule a similaridade de Jaccard entre os dois documentos mais similares conforme o produto escalar\n",
        "# Dica: você pode utilizar a classe set() do python para transformar listas de palavras em conjuntos e aplicar suas operações\n",
        "# Você pode usar as variáveis d_sim_pe_words e d1_words para verificar as palavras em cada documento\n",
        "v1 = set(d_sim_pe_words)\n",
        "v2 = set(d1_words)\n",
        "\n",
        "jaccard = similaridade_jaccard(v1, v2)\n",
        "\n",
        "print(f\"Similaridade de Jaccard: {jaccard:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69VDBY7OAQ0g",
        "outputId": "19f58785-cfd1-4f94-e542-f99b81363068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similaridade de Jaccard: 0.0714\n"
          ]
        }
      ],
      "source": [
        "# Calcule a similaridade de Jaccard entre os dois documentos retornados anteriormente em relação à d1\n",
        "# Dica: você pode utilizar a classe set() do python para transformar listas de palavras em conjuntos e aplicar suas operações\n",
        "# Você pode usar as variáveis d_sim_cos_words e d1_words para verificar as palavras em cada documento\n",
        "v1 = set(d_sim_cos_words)\n",
        "v2 = set(d1_words)\n",
        "\n",
        "jaccard = similaridade_jaccard(v1, v2)\n",
        "\n",
        "print(f\"Similaridade de Jaccard: {jaccard:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P7cUr4GFznS"
      },
      "source": [
        "## 2. Agora vamos avançar para uma abordagem que permite representar **textos inteiros** como vetores: o modelo **Bag of Words (BoW)**.\n",
        "\n",
        "A ideia do BoW é simples, mas poderosa:  \n",
        "Cada documento (ou frase) é representado por um vetor que **conta quantas vezes cada palavra do vocabulário aparece** naquele texto.\n",
        "\n",
        "\n",
        "Refaça os passos da etapa 1, agora utilizando a contagem de cada palavra!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "W88mhutuGTSZ"
      },
      "outputs": [],
      "source": [
        "#Gere um novo vetorizador e armazene na variável vectorizer_bow\n",
        "#Você pode fazer isso utilizando a classe CountVectorizer() sem nenhum parâmetro\n",
        "vectorizer_bow = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3JMZOqjF6lV",
        "outputId": "5070a296-9bd8-4c34-80b2-890599a1a5d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['aaargh' 'aaliyah' 'aamir' 'aaron' 'ab' 'abandon' 'abba' 'abbey' 'abbot'\n",
            " 'abbott']\n"
          ]
        }
      ],
      "source": [
        "#É possível vetorizar o dataframe passando df['nome_coluna'] como parâmetro para seu vetorizador\n",
        "#Armazene a vetorização na variável bow_response\n",
        "#Recupere cada palavra resultante da vetorização. Dica: use a função get_feature_names_out() do seu vetorizador\n",
        "\n",
        "bow_response = vectorizer_bow.fit_transform(df['review'])\n",
        "bow_words = vectorizer_bow.get_feature_names_out()\n",
        "\n",
        "print(bow_words[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "akHfjqDwGdgC",
        "outputId": "fe870070-c222-4986-8b78-b081eb8f70ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aaargh</th>\n",
              "      <th>aaliyah</th>\n",
              "      <th>aamir</th>\n",
              "      <th>aaron</th>\n",
              "      <th>ab</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abba</th>\n",
              "      <th>abbey</th>\n",
              "      <th>abbot</th>\n",
              "      <th>abbott</th>\n",
              "      <th>...</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zoology</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zp</th>\n",
              "      <th>zu</th>\n",
              "      <th>zucker</th>\n",
              "      <th>zulu</th>\n",
              "      <th>zwick</th>\n",
              "      <th>zzzzzzzzzzzzzzzzzz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 17431 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   aaargh  aaliyah  aamir  aaron  ab  abandon  abba  abbey  abbot  abbott  \\\n",
              "0       0        0      0      0   0        0     0      0      0       0   \n",
              "1       0        0      0      0   0        0     0      0      0       0   \n",
              "2       0        0      0      0   0        0     0      0      0       0   \n",
              "3       0        0      0      0   0        0     0      0      0       0   \n",
              "4       0        0      0      0   0        0     0      0      0       0   \n",
              "\n",
              "   ...  zone  zoo  zoology  zoom  zp  zu  zucker  zulu  zwick  \\\n",
              "0  ...     0    0        0     0   0   0       0     0      0   \n",
              "1  ...     0    0        0     0   0   0       0     0      0   \n",
              "2  ...     0    0        0     0   0   0       0     0      0   \n",
              "3  ...     0    0        0     0   0   0       0     0      0   \n",
              "4  ...     0    0        0     0   0   0       0     0      0   \n",
              "\n",
              "   zzzzzzzzzzzzzzzzzz  \n",
              "0                   0  \n",
              "1                   0  \n",
              "2                   0  \n",
              "3                   0  \n",
              "4                   0  \n",
              "\n",
              "[5 rows x 17431 columns]"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Transforme seus vetores em um dataframe para trabalhar com essa estrutura de dados, use os vetores da célula anterior e as palavras obtidas\n",
        "#Você pode fazer isso chamando a classe pd.DataFrame(vetores, columns=['nome de cada coluna'])\n",
        "bow_df = pd.DataFrame(bow_response.toarray(), columns=vectorizer_bow.get_feature_names_out())\n",
        "\n",
        "bow_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKhywzEkG-Jq",
        "outputId": "e619e8e9-9fb5-4e5d-d699-95a69b10b6c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['accustom', 'agenda', 'agreement', 'appeal', 'around', 'audience', 'away', 'awayi', 'become', 'bitch']\n"
          ]
        }
      ],
      "source": [
        "# Recupere o primeiro documento e armazene na variável bow_d1\n",
        "# Você pode fazer isso recuperando o elemento índice 0 no dataframe usando a função loc.\n",
        "\n",
        "# Imprima quais palavras fazem parte de bow_d1\n",
        "# Para cada posição desse vetor, se ele for diferente de 0, então você pode manter essa palavra usando a variável index do bow_d1\n",
        "bow_d1 = bow_df.loc[0]\n",
        "\n",
        "bow_d1_words = [token for token, value in bow_d1.items() if value == 1]\n",
        "print(bow_d1_words[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ8rmFbZIIRu",
        "outputId": "0de6b4cc-6def-4e3c-abf1-b4b83f5abe3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Produto escalar: 152\n",
            "Id do documento: 804\n",
            "\n",
            "Similaridade do cosseno: 0.3523\n",
            "Id do documento: 804\n"
          ]
        }
      ],
      "source": [
        "# Encontre os ids dos documentos mais similares ao documento d1 percorrendo o restante do dataframe e retorne seus índices\n",
        "# Utilize o produto escalar e a similaridade do cosseno da função já disponível para achar os documentos similares por essas duas métricas\n",
        "# Calcule cada similaridade separadamente e verifique se o documento retornado é igual\n",
        "# Use a implementação da seção anterior\n",
        "\n",
        "#Variáveis para armazenar o id do documento mais similar conforme a similaridade do cosseno\n",
        "sim_cos = -1\n",
        "id_sc = -1\n",
        "\n",
        "#Variáveis para armazenar o id do documento mais similar conforme o produto escalar\n",
        "prod_esc = -1\n",
        "id_pe = -1\n",
        "\n",
        "for idx, row in bow_df.iloc[1:].iterrows():\n",
        "  \n",
        "  novo_es = np.dot(row, bow_d1)\n",
        "  \n",
        "  if novo_es > prod_esc:\n",
        "    prod_esc = novo_es\n",
        "    id_pe = idx\n",
        "\n",
        "  #Calcule o produto escalar e salve o documento de maior similaridade\n",
        "  #Você pode usar a função np.dot() passando seus vetores para calcular o produto escalar\n",
        "  \n",
        "  novo_cs = similaridade_cosseno(row, bow_d1)\n",
        "  \n",
        "  if novo_cs > sim_cos:\n",
        "    sim_cos = novo_cs\n",
        "    id_sc = idx\n",
        "\n",
        "\n",
        "  #Calcule a Similaridade do cosseno e salve o documento de maior similaridade\n",
        "  #Você pode usar a função de similaridade do cosseno presente no início deste notebook passando seus vetores\n",
        "\n",
        "\n",
        "print(f\"Produto escalar: {prod_esc}\")\n",
        "print(\"Id do documento:\", id_pe)\n",
        "print()\n",
        "print(f\"Similaridade do cosseno: {sim_cos:.4f}\")\n",
        "print(\"Id do documento:\", id_sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAG04X0FKn0E",
        "outputId": "61818853-e3c3-4cb8-f233-258361525fb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['absolutely', 'act', 'actor', 'afraid', 'agree', 'always', 'anyone', 'appalled', 'believe', 'best']\n"
          ]
        }
      ],
      "source": [
        "# Mostre as 10 primeiras palavras presentes do documento retornado por possuir maior produto escalar\n",
        "# Você pode recuperar esse vetor usando o índice salvo em id_pe\n",
        "\n",
        "d_sim_pe = bow_df.loc[id_pe]\n",
        "d_sim_pe_words = [token for token, value in d_sim_pe.items() if value != 0]\n",
        "\n",
        "print(d_sim_pe_words[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UwexDUuKyGC",
        "outputId": "3ca3ccc5-97c2-4775-de73-352fde3f5c9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['absolutely', 'act', 'actor', 'afraid', 'agree', 'always', 'anyone', 'appalled', 'believe', 'best']\n"
          ]
        }
      ],
      "source": [
        "# Mostre as 10 primeiras palavras presentes do documento retornado por possuir maior similaridade do cosseno\n",
        "# Você pode recuperar esse vetor usando o índice salvo em id_sc\n",
        "d_sim_cos = bow_df.loc[id_sc]\n",
        "d_sim_cos_words = [token for token, value in d_sim_cos.items() if value != 0]\n",
        "\n",
        "print(d_sim_cos_words[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMCsVf3TK22H"
      },
      "source": [
        "## 3. 📊 TF-IDF (Term Frequency - Inverse Document Frequency)\n",
        "\n",
        "Até agora, usamos a contagem para representar o peso de uma palavra em um documento.\n",
        "\n",
        "Mas pense bem: palavras como \"o\", \"e\", \"no\", \"de\" aparecem o tempo todo em quase todos os textos. Mesmo que sejam frequentes, **elas não carregam muito significado específico**.\n",
        "\n",
        "É aí que entra o **TF-IDF**: uma técnica que ajusta o TF penalizando palavras que são comuns em muitos documentos e destacando aquelas que são mais **específicas** de um documento.\n",
        "\n",
        "##### 🧠 Como funciona o TF-IDF?\n",
        "\n",
        "- **TF**: frequência relativa da palavra no documento.\n",
        "- **IDF**: mede o quão rara (ou informativa) a palavra é em todo o corpus.\n",
        "- O TF-IDF final é o produto entre esses dois valores.\n",
        "\n",
        "O resultado é uma representação vetorial mais equilibrada, que valoriza as palavras **relevantes**, não apenas as **frequentes**.\n",
        "\n",
        "Agora vamos aplicar isso ao nosso corpus!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "DmwoFj7KK7uF"
      },
      "outputs": [],
      "source": [
        "#Crie o vetorizador dessa etapa. Você pode fazer isso utilizando a classe TfidfVectorizer() sem parâmetro.\n",
        "#Crie seu vetorizador em uma variável chamada tfidf_vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06hE5cQkMU6L",
        "outputId": "e7fb400f-2f96-436a-8746-caf666ad0238"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['aaargh', 'aaliyah', 'aamir', 'aaron', 'ab', 'abandon', 'abba',\n",
              "       'abbey', 'abbot', 'abbott'], dtype=object)"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#É possível vetorizar o dataframe passando df['nome_coluna'] como parâmetro para seu vetorizador\n",
        "#Armazene a vetorização na variável tfidf_response\n",
        "#Recupere cada palavra resultante da vetorização. Dica: use a função get_feature_names_out() do seu vetorizador\n",
        "tfidf_response = tfidf_vectorizer.fit_transform(df['review'])\n",
        "tfidf_words = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "tfidf_words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "HjkPGokIMnW2",
        "outputId": "7f595799-1792-4c84-e98c-eb0d26f8178d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aaargh</th>\n",
              "      <th>aaliyah</th>\n",
              "      <th>aamir</th>\n",
              "      <th>aaron</th>\n",
              "      <th>ab</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abba</th>\n",
              "      <th>abbey</th>\n",
              "      <th>abbot</th>\n",
              "      <th>abbott</th>\n",
              "      <th>...</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zoology</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zp</th>\n",
              "      <th>zu</th>\n",
              "      <th>zucker</th>\n",
              "      <th>zulu</th>\n",
              "      <th>zwick</th>\n",
              "      <th>zzzzzzzzzzzzzzzzzz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 17431 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   aaargh  aaliyah  aamir  aaron   ab  abandon  abba  abbey  abbot  abbott  \\\n",
              "0     0.0      0.0    0.0    0.0  0.0      0.0   0.0    0.0    0.0     0.0   \n",
              "1     0.0      0.0    0.0    0.0  0.0      0.0   0.0    0.0    0.0     0.0   \n",
              "2     0.0      0.0    0.0    0.0  0.0      0.0   0.0    0.0    0.0     0.0   \n",
              "3     0.0      0.0    0.0    0.0  0.0      0.0   0.0    0.0    0.0     0.0   \n",
              "4     0.0      0.0    0.0    0.0  0.0      0.0   0.0    0.0    0.0     0.0   \n",
              "\n",
              "   ...  zone  zoo  zoology  zoom   zp   zu  zucker  zulu  zwick  \\\n",
              "0  ...   0.0  0.0      0.0   0.0  0.0  0.0     0.0   0.0    0.0   \n",
              "1  ...   0.0  0.0      0.0   0.0  0.0  0.0     0.0   0.0    0.0   \n",
              "2  ...   0.0  0.0      0.0   0.0  0.0  0.0     0.0   0.0    0.0   \n",
              "3  ...   0.0  0.0      0.0   0.0  0.0  0.0     0.0   0.0    0.0   \n",
              "4  ...   0.0  0.0      0.0   0.0  0.0  0.0     0.0   0.0    0.0   \n",
              "\n",
              "   zzzzzzzzzzzzzzzzzz  \n",
              "0                 0.0  \n",
              "1                 0.0  \n",
              "2                 0.0  \n",
              "3                 0.0  \n",
              "4                 0.0  \n",
              "\n",
              "[5 rows x 17431 columns]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Transforme seus vetores em um dataframe para trabalhar com essa estrutura de dados, use os vetores da célula anterior e as palavras obtidas\n",
        "#Você pode fazer isso chamando a classe pd.DataFrame(vetores, columns=['nome de cada coluna'])\n",
        "\n",
        "tfidf_df = pd.DataFrame(tfidf_response.toarray(), columns=tfidf_words)\n",
        "tfidf_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoBlr9VXMy9Y",
        "outputId": "3eb2f67a-7aa3-4220-adc5-f370c743fb7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['accustom', 'agenda', 'agreement', 'appeal', 'around', 'audience', 'away', 'awayi', 'become', 'bitch']\n"
          ]
        }
      ],
      "source": [
        "# Recupere o primeiro documento e armazene na variável bow_d1\n",
        "# Você pode fazer isso, recuperando o elemento índice 0 no dataframe.\n",
        "\n",
        "# Imprima quais palavras fazem parte de seu vetor\n",
        "# Para cada posição desse vetor, se ele for diferente de 0, então você pode manter sua palavra usando a variável index do tfidf_d1\n",
        "\n",
        "tfidf_d1 = tfidf_df.loc[0]\n",
        "\n",
        "tfidf_d1_words = [token for token, value in tfidf_d1.items() if value != 0]\n",
        "\n",
        "print(tfidf_d1_words[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZENJZ7h7OyTn",
        "outputId": "05f392f7-7ba9-4fc3-dc67-1b94fbb493aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Produto escalar: 0.16070948359757772\n",
            "Id do documento: 804\n",
            "\n",
            "Similaridade do cosseno: 0.1607\n",
            "Id do documento: 804\n"
          ]
        }
      ],
      "source": [
        "# Encontre os ids dos documentos mais similares ao documento d1 percorrendo o restante do dataframe e retorne seus índices\n",
        "# Utilize o produto escalar e a similaridade do cosseno da função já disponível para achar os documentos similares por essas duas métricas\n",
        "# Calcule cada similaridade separadamente e verifique se o documento retornado é igual\n",
        "# Use a implementação da seção anterior\n",
        "\n",
        "#Variáveis para armazenar o id do documento mais similar conforme a similaridade do cosseno\n",
        "sim_cos = -1\n",
        "id_sc = -1\n",
        "\n",
        "#Variáveis para armazenar o id do documento mais similar conforme o produto escalar\n",
        "prod_esc = -1\n",
        "id_pe = -1\n",
        "\n",
        "for idx, row in tfidf_df.iloc[1:].iterrows():\n",
        "\n",
        "  #Calcule o produto escalar e salve o documento de maior similaridade\n",
        "  #Você pode usar a função np.dot() passando seus vetores para calcular o produto escalar\n",
        "\n",
        "  novo_escalar = np.dot(row, tfidf_d1)\n",
        "  \n",
        "  if novo_escalar > prod_esc:\n",
        "    prod_esc = novo_escalar\n",
        "    id_pe = idx\n",
        "    \n",
        "  novo_cosseno = similaridade_cosseno(row,tfidf_d1)\n",
        "  \n",
        "  if novo_cosseno > sim_cos:\n",
        "    sim_cos = novo_cosseno\n",
        "    id_sc = idx\n",
        "\n",
        "\n",
        "  #Calcule a Similaridade do cosseno e salve o documento de maior similaridade\n",
        "  #Você pode usar a função de similaridade do cosseno presente no início deste notebook passando seus vetores\n",
        "\n",
        "print(f\"Produto escalar: {prod_esc}\")\n",
        "print(\"Id do documento:\", id_pe)\n",
        "print()\n",
        "print(f\"Similaridade do cosseno: {sim_cos:.4f}\")\n",
        "print(\"Id do documento:\", id_sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO5vgxIyPDGq",
        "outputId": "fe8f29b8-b32f-44a8-e2fb-9d1d10e2b5ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['absolutely', 'act', 'actor', 'afraid', 'agree', 'always', 'anyone', 'appalled', 'believe', 'best']\n"
          ]
        }
      ],
      "source": [
        "# Mostre as 10 primeiras palavras presentes do documento retornado por possuir maior produto escalar\n",
        "# Você pode recuperar esse vetor usando o índice salvo em id_pe\n",
        "d_sim_pe = tfidf_df.loc[id_pe]\n",
        "\n",
        "d_sim_pe_words = [token for token, value in d_sim_pe.items() if value != 0]\n",
        "\n",
        "print(d_sim_pe_words[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6694AfTkPQiY",
        "outputId": "13fc2157-1377-4bde-8d32-422ec75aded7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['absolutely',\n",
              " 'act',\n",
              " 'actor',\n",
              " 'afraid',\n",
              " 'agree',\n",
              " 'always',\n",
              " 'anyone',\n",
              " 'appalled',\n",
              " 'believe',\n",
              " 'best']"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mostre as 10 primeiras palavras presentes do documento retornado por possuir maior similaridade do cosseno\n",
        "# Você pode recuperar esse vetor usando o índice salvo em id_sc\n",
        "d_sim_cos = tfidf_df.loc[id_sc]\n",
        "\n",
        "d_sim_cos_words = [token for token, value in d_sim_cos.items() if value != 0]\n",
        "d_sim_cos_words[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYFLQZlQ0vMO"
      },
      "source": [
        "#### **Perguntas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHzCQS2p1A89"
      },
      "source": [
        "1. **Ao se utilizar estratégias diferentes de vetorização, o resultado do documento mais similar se manteve igual? Justifique (considere a similaride do cosseno)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_li1YUm1Dof"
      },
      "source": [
        "2. **Ao se utilizar métricas de similaridade diferentes o resultado do documento mais similar se manteve igual? Justifique (considere qualquer forma de vetorização)**  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDbXPiHl8zpW"
      },
      "source": [
        "## KNN\n",
        "O **k-NN (k-Nearest Neighbors)** é um algoritmo de classificação baseado em **proximidade**. Em PLN, usamos representações vetoriais dos textos para comparar semelhanças entre documentos.\n",
        "\n",
        "A lógica do algoritmo é simples:\n",
        "\n",
        "> Dado um novo texto, o k-NN procura os **k textos mais próximos** no conjunto de treinamento e decide a **classe mais comum** entre esses vizinhos.\n",
        "\n",
        "A \"proximidade\" entre os textos vetorizados é determinada por uma **métrica de distância**, como:\n",
        "\n",
        "- 🧮 **Distância Euclidiana** (métrica padrão)\n",
        "- 📏 **Distância Manhattan** (soma das diferenças absolutas)\n",
        "- 🧊 **Distância Chebyshev** (maior diferença em uma dimensão)\n",
        "\n",
        "Essa abordagem nos permite:\n",
        "\n",
        "- Classificar textos com base em exemplos anteriores\n",
        "- Explorar como diferentes métricas de distância afetam os resultados\n",
        "- Analisar se a **classificação faz sentido com base nas palavras presentes**\n",
        "\n",
        "Neste experimento, vamos utilizar k-NN para prever o sentimento (positivo ou negativo) dos comentários vetorizados anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcXzejsdP6HF",
        "outputId": "9ab4836e-3eac-4001-8efe-c5337b5b2993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0      1\n",
            "1      1\n",
            "2      1\n",
            "3      0\n",
            "4      1\n",
            "      ..\n",
            "995    1\n",
            "996    0\n",
            "997    0\n",
            "998    0\n",
            "999    0\n",
            "Name: sentiment, Length: 1000, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Defina aqui os rótulos, busque no dataset qual coluna carrega o sentimento do comentário\n",
        "# Para acessar a coluna do dataframe basta utilizar dataframe['nome da coluna']\n",
        "rotulos = df['sentiment']\n",
        "\n",
        "print(rotulos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "WWgpDcwI797G"
      },
      "outputs": [],
      "source": [
        "# Defina aqui qual modelo vetorizado será utilizado, podendo ser o bow ou o td-idf que foi utilizado na etapa anterior\n",
        "# Utilize a variável que já armazena os dados vetorizados e salve na variável textos\n",
        "\n",
        "textos = bow_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 17431)"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "textos.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "fLa7u6b82s1c"
      },
      "outputs": [],
      "source": [
        "# Separe aqui os textos na parte de treino e na parte de teste, deixando 20% dos dados para teste. Para isso utilize a função train_test_split()\n",
        "# A função train_test_split() espera receber os textos, rótulos, test_size para separação em treino e teste e random_state. Use random_state=42 para evitar aleatoriedade\n",
        "# Essa função retorna 4 informações: X_treino, X_teste, Y_treino, Y_teste\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(textos, rotulos, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "gOAB-lp53k9e"
      },
      "outputs": [],
      "source": [
        "# Trecho já pronto, não é necessário mudá-lo\n",
        "metricas = ['euclidean', 'manhattan', 'chebyshev']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "R-h96EoD-Att"
      },
      "outputs": [],
      "source": [
        "# Defina aqui o valor da quantidade de vizinhos proximos\n",
        "# Sinta-se à vontade para experimentar e buscar os melhores valores de K\n",
        "k = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOFP_yLF3mtn",
        "outputId": "1113f860-ba4c-421f-fe90-7c81892e8baf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Distância: EUCLIDEAN\n",
            "📌 Texto: one best ensemble act film ive ever see isnt much plot act incredible see character change ever subtly undr influence rent villa italy love happiness film cast mesmerize spell much villa woman truly enchant\n",
            "✅ Classe real: 1\n",
            "📈 Classe prevista: 1\n",
            "👥 Documentos mais próximos:\n",
            "1. \"film contain far much meaningless violence much shoot blood act seem unrealistic generally poor reason see film like old car\" → classe: 0\n",
            "2. \"mystery men get stupidest film ive ever see film thought fabulous excellent impressive funny welldone nice see ridiculous super hero change able pull great ill definitely watch\" → classe: 1\n",
            "3. \"unpretentious horror film probably destine become cult classic much much well scream ripoffs even hope come sequel\" → classe: 1\n",
            "4. \"rating not begin express dull depress relentlessly bad movie\" → classe: 0\n",
            "5. \"see film least time still excite act perfect romance joe jean keep edge seat plus still think bryan brown top brilliant film\" → classe: 1\n",
            "6. \"feel mislike russian film see film unique masterpiece make best director ever live ussr know art film make use well find movie buy copy\" → classe: 1\n",
            "7. \"great film touch strong direction without question breathless good work team feel sorry marlene grace god go\" → classe: 1\n",
            "8. \"theyve show twice short time sweden tire bad act isnt enough story boring effect hardly exists love original recommend go rent one instead one bore\" → classe: 0\n",
            "9. \"film take one family impossible journey make feel every step odyssey beautifully act photograph heartbreakingly real last line wistful hope one powerful memory\" → classe: 1\n",
            "10. \"highly regard release since rather neglect immense importance history perform art classic use embed plot one favourite film hasnt soundtrack rereleased\" → classe: 1\n",
            "\n",
            "🔍 Distância: MANHATTAN\n",
            "📌 Texto: one best ensemble act film ive ever see isnt much plot act incredible see character change ever subtly undr influence rent villa italy love happiness film cast mesmerize spell much villa woman truly enchant\n",
            "✅ Classe real: 1\n",
            "📈 Classe prevista: 1\n",
            "👥 Documentos mais próximos:\n",
            "1. \"film contain far much meaningless violence much shoot blood act seem unrealistic generally poor reason see film like old car\" → classe: 0\n",
            "2. \"rating not begin express dull depress relentlessly bad movie\" → classe: 0\n",
            "3. \"unpretentious horror film probably destine become cult classic much much well scream ripoffs even hope come sequel\" → classe: 1\n",
            "4. \"mystery men get stupidest film ive ever see film thought fabulous excellent impressive funny welldone nice see ridiculous super hero change able pull great ill definitely watch\" → classe: 1\n",
            "5. \"see film least time still excite act perfect romance joe jean keep edge seat plus still think bryan brown top brilliant film\" → classe: 1\n",
            "6. \"one remarkable scifi movie millennium not movie incredible future vision movie establishes new standard sf movie hail kill\" → classe: 1\n",
            "7. \"feel mislike russian film see film unique masterpiece make best director ever live ussr know art film make use well find movie buy copy\" → classe: 1\n",
            "8. \"great film touch strong direction without question breathless good work team feel sorry marlene grace god go\" → classe: 1\n",
            "9. \"theyve show twice short time sweden tire bad act isnt enough story boring effect hardly exists love original recommend go rent one instead one bore\" → classe: 0\n",
            "10. \"like original gut wrench laughter like movie young old love movie hell even mom like itgreat camp\" → classe: 1\n",
            "\n",
            "🔍 Distância: CHEBYSHEV\n",
            "📌 Texto: one best ensemble act film ive ever see isnt much plot act incredible see character change ever subtly undr influence rent villa italy love happiness film cast mesmerize spell much villa woman truly enchant\n",
            "✅ Classe real: 1\n",
            "📈 Classe prevista: 0\n",
            "👥 Documentos mais próximos:\n",
            "1. \"chinese ghost story iii totally superfluous sequel two excellent fantasy film film delivers spellcasting special effect one expect fails painfully front actor play extremely silly caricature still diaper find slapstick humor even remotely funny plot predictable development sometimes erratic often slow towards end movie begin resemble old godzilla film include shabby largerthanlife special effect well yet another ghost godzilla head maybe would grin expect campit astonish see trash fantasy fan put case somebody thought could squeeze little extra money successful formula wont able cash cow dead dodo\" → classe: 0\n",
            "2. \"funny film like lot cary elwes play robin hood tee course usual good v evil robin evil sheriff nottingham humor sort face stuff part still work well comedy night dont want think much well worth rent\" → classe: 1\n",
            "3. \"plot fizzle reek irreconcilable difference opinion constitute judgmental havoc one side prolife destroyer demon seed horror left replace overall dull effect quite possibly meant horrific instead demonstrate ill dose belief ridicule death despite title fan master horror since begin ridiculous plot twist sordid depiction crashed apart like spindly old rock chair sat upon view episode thrown together get go never really take anywhere see worth relieve finally come end\" → classe: 0\n",
            "4. \"movie great job explain problem face fear put man space history space flight still use today classroom get one rare print disney show vault disney wish would\" → classe: 1\n",
            "5. \"rating not begin express dull depress relentlessly bad movie\" → classe: 0\n",
            "6. \"mystery men get stupidest film ive ever see film thought fabulous excellent impressive funny welldone nice see ridiculous super hero change able pull great ill definitely watch\" → classe: 1\n",
            "7. \"horrible horrible film bad collection cliche see long time not saw much left theatre scream minute search stiff drink soothe nerve meryl streep awful usual many hurt torture expression person aidan quinns talent often totally waste told gloria estefan could act try polically correct movie still enforces racial stereotype brave inexperienced lonely music teacher teach underprivilegded kid violin poor neighbourhood school kid werent even cute write suit appal script aaargh wes craven really make cringe real horror one\" → classe: 0\n",
            "8. \"average surprisingly tame fulci giallo mean still quite bad normal standard redeem solid buildup nice touch neat time twist issue vision clairvoyancethe genre wellknown weakness full gear banal dialogue wooden act illogical plot point finale go much long denouement prof rather lame shall say limp affairfulcis ironic handle giallo norm amuse though yellow clue wherever look limp killer\" → classe: 0\n",
            "9. \"airport basically slop together mess universal studio try work new twist concorde supersonic airliner disasterinthesky formulabogged unintentional humor best george kennedy stick hand concordes window supersonic speed fire flare gun heatseeking missile follow aircraft flight path simple fact dumb passenger keep reboarding plane continue flight despite problem air many star one include robert wagner sylvia kristel alain delon martha raye nervous passenger not really related airport film\" → classe: 0\n",
            "10. \"ever learn ecstatic reviewer npr make think turkey another citizen kane please allow vent spleeni admit set presumably new york city never downright ugly unappealing remind bad decade men fashion automobile smoking plan cheapen character succeededfor film work least simple estimation least one sympathetic character ned beaty come close could not wait finish nicky stray shot struck mikey well may elicit shrug indifference mosti cant remember detest film strongly suppose im rube doesnt dig art flick oh well\" → classe: 0\n"
          ]
        }
      ],
      "source": [
        "#Não é necessário alterar esse trecho\n",
        "for metrica in metricas:\n",
        "    print(f\"\\n🔍 Distância: {metrica.upper()}\")\n",
        "\n",
        "    #Treinando o modelo\n",
        "    knn = KNeighborsClassifier(n_neighbors=k, metric=metrica)\n",
        "    knn.fit(X_train.toarray(), y_train)\n",
        "\n",
        "    # Escolhendo um exemplo de teste\n",
        "    X_exemplo = X_test[0]\n",
        "    y_exemplo = y_test.iloc[0]\n",
        "    texto_exemplo = df['review'][y_test.index[0]]\n",
        "\n",
        "    # Classificando\n",
        "    pred = knn.predict([X_exemplo.toarray()[0]])\n",
        "\n",
        "    print(f\"📌 Texto: {texto_exemplo}\")\n",
        "    print(f\"✅ Classe real: {y_exemplo}\")\n",
        "    print(f\"📈 Classe prevista: {pred[0]}\")\n",
        "\n",
        "    # Listando os K vizinhos mais próximos\n",
        "    dist, idxs = knn.kneighbors([X_exemplo.toarray()[0]])\n",
        "    print(\"👥 Documentos mais próximos:\")\n",
        "    for i, idx in enumerate(idxs[0]):\n",
        "        viz_texto = df['review'].iloc[y_train.index[idx]]\n",
        "        viz_label = y_train.iloc[idx]\n",
        "        print(f\"{i+1}. \\\"{viz_texto}\\\" → classe: {viz_label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydqcX523dagf"
      },
      "source": [
        "# Perguntas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15D2l6qZ29eU"
      },
      "source": [
        "Responda as duas perguntas seguintes considerando k = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnSqRLnrfnxT"
      },
      "source": [
        "**1 . Ao se utilizar métricas de distância diferentes, a classificação do documento é igual ao seu rótulo original? Se não, quais métricas resultam em classificação diferente?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjRBm_te4WHg"
      },
      "source": [
        "Resposta:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7egQGJH5kfvF"
      },
      "source": [
        "**2 . Algum documento se repete como mais similar independemente da métrica? Se sim? Quais palavras ele possui em comum com o documento original?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKrQU6TH4afN"
      },
      "source": [
        "Resposta:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HX2cR0Z3I7f"
      },
      "source": [
        "Responda a pergunta a seguir considerando k maior ou igual a 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfJEAPeTzVAl"
      },
      "source": [
        "**3 . Se aumentarmos k, a classificação do documento continua igual ao seu rótulo original independemente da métrica? Se não, qual métrica faz com que a classificação seja incorreta?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-YRRAOb4cAj"
      },
      "source": [
        "Resposta:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmiiTSLe378k"
      },
      "source": [
        "**4 . Alguma métrica de distância apresentou um resultado de classificação consistente independentemente da vetorização e do tamanho de K? Se sim, qual?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdT0PKG04d65"
      },
      "source": [
        "Resposta:"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
